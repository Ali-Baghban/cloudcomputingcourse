**************************************************************************************************
* Isfahan University of Technology | Cloud Computing-401/1 | Dr. Zali | Directed by: Ali Baghban *
**************************************************************************************************
# sudo su
# apt update
# apt install openjdk-8-jdk -y

# wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.4/hadoop-3.3.4.tar.gz

# tar -xzvf hadoop-3.3.4.tar.gz
# mv hadoop-3.3.4 /usr/local/hadoop

# nano /etc/environment 
update with adding after other pathes >> ":/usr/local/hadoop/bin:/usr/local/hadoop/sbin"
add this line under the " >> JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
--------------------------------------------
Do these steps for master and workers:

# adduser hadoop
# usermod -aG hadoop hadoop
# chown hadoop:root -R /usr/local/hadoop
# chmod g+rwx -R /usr/local/hadoop
--------------------------------------------
Do these steps only for master: 

# su - hadoop
# ssh-keygen -t rsa 
# cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
# chmod og-wx ~/.ssh/authorized_keys
# su - hadoop
$ ssh-copy-id hadoop@slave1
$ ssh-copy-id hadoop@slave2

-------------------------------------------
Do these steps for master and workers:

# nano  /usr/local/hadoop/etc/hadoop/core-site.xml
open and add:
<configuration>
  <property>
    <name>fs.default.name</name>
    <value>hdfs://master:9000</value>
  </property>
</configuration>
-----
for Master:
# nano /usr/local/hadoop/etc/hadoop/hdfs-site.xml
open and add:

<configuration>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>/usr/local/hadoop/data/nameNode</value>
  </property>
  <property>
    <name>dfs.hosts</name>
    <value>slave1,slave2</value>
  </property>
  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>
</configuration>
-----
for Workers:
# nano /usr/local/hadoop/etc/hadoop/hdfs-site.xml
open and add:

<configuration>
  <property>
    <name>dfs.datanode.data.dir</name>
    <value>/usr/local/hadoop/data/dataNode</value>
  </property>
</configuration>
-------
for Master:
# nano /usr/local/hadoop/etc/hadoop/yarn-site.xml
open and add:

<configuration>
<property>
    <name>yarn.nodemanager.resource.memory-mb</name>
    <value>1536</value>
</property>
<property>
    <name>yarn.scheduler.maximum-allocation-mb</name>
    <value>1536</value>
</property>
<property>
    <name>yarn.scheduler.minimum-allocation-mb</name>
    <value>128</value>
</property>
<property>
    <name>yarn.nodemanager.vmem-check-enabled</name>
    <value>false</value>
</property>

<property>
    <name>yarn.resourcemanager.address</name>
    <value>http://master:8032</value>
</property>
<property>
        <name>yarn.nodemanager.remote-app-log-dir</name>
        <value>/usr/local/hadoop/logs/</value>
</property>
</configuration>
-----
for Workers:
# nano /usr/local/hadoop/etc/hadoop/yarn-site.xml
open and add:

<configuration>
  <property>
    <name>yarn.resourcemanager.address</name>
    <value>http://master:8032</value>
  </property>
   <property>
    <name>yarn.resourcemanager.hostname</name>
    <value>master</value>
  </property>
</configuration>
-----
for Master only:
# nano /usr/local/hadoop/etc/hadoop/mapred-site.xml
open and add:

<configuration>
        <property>
                <name>mapreduce.jobhistory.address</name>
                <value>http://master:10020</value>
        </property>
        <property>
                <name>mapreduce.jobhistory.webapp.address</name>
                <value>http://master:19888</value>
        </property>
        <property>
                <name>mapreduce.jobhistory.intermediate-done-dir</name>
                <value>/usr/local/hadoop/data/mr-history/tmp</value>
        </property>
        <property>
                <name>mapreduce.jobhistory.done-dir</name>
                <value>/usr/local/hadoop/data/mr-history/done</value>
        </property>

</configuration>
-----
for Master and Workers:
# nano /usr/local/hadoop/etc/hadoop/workers
open and add:

slave1
slave2
-------------------------------------------
-------------------------------------------
Extra conf. for compiling java (Mapreduce) code

# export HADOOP_CLASSPATH=${JAVA_HOME}/lib/tools.jar
